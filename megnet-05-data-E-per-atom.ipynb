{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymatgen\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from data import get_dichalcogenides_innopolis_202105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82288dbe1a324c77a4f2899a5707c669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/temporary/pymatgen/pymatgen/io/cif.py:1123: UserWarning:\n",
      "\n",
      "Issues encountered while parsing CIF: Some fractional co-ordinates rounded to ideal values to avoid issues with finite precision.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "structures = get_dichalcogenides_innopolis_202105()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "from megnet.models import MEGNetModel\n",
    "from megnet.data.graph import GaussianDistance\n",
    "from megnet.data.crystal import CrystalGraph\n",
    "from megnet.data.molecule import MolecularGraph\n",
    "from megnet.utils.preprocessing import StandardScaler\n",
    "from megnet.callbacks import ModelCheckpointMAE\n",
    "from pymatgen.core import Lattice, Structure, Molecule\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(structures, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkazeev\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">amber-flower-17</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kazeev/ai4material_design\" target=\"_blank\">https://wandb.ai/kazeev/ai4material_design</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kazeev/ai4material_design/runs/c8s1vvf9\" target=\"_blank\">https://wandb.ai/kazeev/ai4material_design/runs/c8s1vvf9</a><br/>\n",
       "                Run data is saved locally in <code>/temporary/ai4material_design/wandb/run-20210712_142545-c8s1vvf9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(c8s1vvf9)</h1><iframe src=\"https://wandb.ai/kazeev/ai4material_design/runs/c8s1vvf9\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8da6881320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='ai4material_design', entity='kazeev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config\n",
    "config.target = \"energy_per_atom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = CrystalGraph(bond_converter=GaussianDistance(np.linspace(0, 5, 100), 0.5), cutoff=6)\n",
    "model = MEGNetModel(nfeat_edge=100, nfeat_global=2, graph_converter=gc, npass=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler.from_training_data(train[\"initial_structure\"],\n",
    "                                           train[config.target], is_intensive=True)\n",
    "model.target_scaler = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_atom/Reshape_9:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_atom/Reshape_8:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_atom/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_bond/Reshape_9:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_bond/Reshape_8:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_bond/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_atom/Reshape_27:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_atom/Reshape_26:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_atom/Cast_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_bond/Reshape_27:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_bond/Reshape_26:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_bond/Cast_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_atom/Reshape_45:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_atom/Reshape_44:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_atom/Cast_4:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_bond/Reshape_45:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_bond/Reshape_44:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_bond/Cast_4:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_atom/Reshape_63:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_atom/Reshape_62:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_atom/Cast_6:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_bond/Reshape_63:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_bond/Reshape_62:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_bond/Cast_6:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_atom/Reshape_81:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_atom/Reshape_80:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_atom/Cast_8:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_bond/Reshape_81:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_bond/Reshape_80:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_bond/Cast_8:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 79s 3s/step - loss: 0.0510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00001: val_mae improved from inf to 0.04380, saving model to callback/val_mae_00001_0.043804.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00002: val_mae improved from 0.04380 to 0.03522, saving model to callback/val_mae_00002_0.035225.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0660\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0889\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0583\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0486\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00007: val_mae improved from 0.03522 to 0.03431, saving model to callback/val_mae_00007_0.034310.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0380\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0391\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0471\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0348\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0482\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0548\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00014: val_mae improved from 0.03431 to 0.03366, saving model to callback/val_mae_00014_0.033663.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0494\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0372\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0551\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0487\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0489\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0438\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0429\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0357\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0623\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 58s 3s/step - loss: 0.0478\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0453\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0609\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0538\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0643\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0468\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0491\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0504\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0473\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0484\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0802\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0609\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0583\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0442\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0581\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0377\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0468\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0436\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0401\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0509\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0671\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0520\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 73s 3s/step - loss: 0.0494\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 87s 4s/step - loss: 0.0629\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 81s 4s/step - loss: 0.0508\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 89s 4s/step - loss: 0.0604\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 87s 4s/step - loss: 0.0394\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 84s 4s/step - loss: 0.0488\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 86s 4s/step - loss: 0.0467\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 85s 4s/step - loss: 0.0396\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 88s 4s/step - loss: 0.0466\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 91s 4s/step - loss: 0.0531\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 81s 4s/step - loss: 0.0542\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 82s 4s/step - loss: 0.0430\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 89s 4s/step - loss: 0.0569\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 85s 4s/step - loss: 0.0521\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 86s 4s/step - loss: 0.0404\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 85s 4s/step - loss: 0.0493\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 80s 4s/step - loss: 0.0651\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 87s 4s/step - loss: 0.0503\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 87s 4s/step - loss: 0.0529\n",
      "Epoch 65/1000\n",
      "13/21 [=================>............] - ETA: 32s - loss: 0.0235"
     ]
    }
   ],
   "source": [
    "model.train(train[\"initial_structure\"], train[config.target],\n",
    "            validation_structures=test[\"initial_structure\"],\n",
    "            validation_targets=test[config.target],\n",
    "            callbacks=[WandbCallback()],\n",
    "            epochs=1000, verbose=1, patience=1000, prev_model=\"callback/val_mae_00085_0.034367.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"megnet-05-data-E-per-atom-1k-epochs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
