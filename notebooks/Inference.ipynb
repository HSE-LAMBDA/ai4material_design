{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "In this notebook we load the pre-trained models, generate or upload some structures, and predict their defect formation energy per site and HOMO-LUMO gap. For magnetic structures, the models predict the minimum of spin-up and spin-down HOMO-LUMO gaps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "If we are on Constructor Research Platform (CRP), limit us to the CPUs available there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'ROLOS_AVAILABLE_CPU' in os.environ:\n",
    "    for variable in (\"MKL_NUM_THREADS\", \"NUMEXPR_NUM_THREADS\", \"OMP_NUM_THREADS\", \"VECLIB_MAXIMUM_THREADS\", \"OPENBLAS_NUM_THREADS\"):\n",
    "        os.environ[variable] = os.environ['ROLOS_AVAILABLE_CPU']\n",
    "    import torch\n",
    "    torch.set_num_threads(int(os.environ['ROLOS_AVAILABLE_CPU']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import yaml\n",
    "import sys\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm, trange\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.io.cif import CifParser\n",
    "\n",
    "import matplotlib\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from ase.visualize.plot import plot_atoms\n",
    "from collections import defaultdict\n",
    "import io\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from ai4mat.models.megnet_pytorch.megnet_on_structures import MEGNetOnStructures\n",
    "from ai4mat.data.data import get_unit_cell, StorageResolver, read_defects_descriptions\n",
    "from ai4mat.common.sparse_representation import get_sparse_defect, SINGLE_ENENRGY_COLUMN\n",
    "from ai4mat.common.random_defect_generation import generate_structure_with_random_defects, InconsistentDefectCount\n",
    "from ai4mat.common.eos import EOS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_experiment = \"combined_mixed_all_train\"\n",
    "model_names = {\n",
    "    \"formation_energy_per_site\": \"megnet_pytorch/sparse/05-12-2022_19-50-53/d6b7ce45\",\n",
    "    \"homo_lumo_gap_min\": \"megnet_pytorch/sparse/05-12-2022_19-50-53/831cc496\"}\n",
    "\n",
    "predictors = dict()\n",
    "for target, trial_name in model_names.items():\n",
    "    with open(StorageResolver()[\"trials\"] / f\"{trial_name}.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    predictors[target] = MEGNetOnStructures(config['model_params'])\n",
    "    predictors[target].load(StorageResolver()[\"checkpoints\"] / training_experiment / target / trial_name / \"0.pth\",\n",
    "                            map_location='cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the parameters of the experiment that the models were trained on. From them we find out which base materials and point defect types were present in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = StorageResolver()[\"experiments\"].joinpath(training_experiment)\n",
    "with open(Path(experiment_path, \"config.yaml\")) as experiment_file:\n",
    "    experiment_config = yaml.safe_load(experiment_file)\n",
    "# We don't check how the data are split inside the experiment\n",
    "# It's the user's responsibility to ensure that the model works on all datasets mentioned\n",
    "training_datasets = experiment_config[\"datasets\"]\n",
    "\n",
    "# Computing EOS takes around a minute, so we use the cache\n",
    "inference_unit_cells_file = StorageResolver()[\"others\"] / \"inference_unit_cells_cache.pkl.gz\"\n",
    "unit_cells_loaded = False\n",
    "try:\n",
    "    with open(inference_unit_cells_file, 'rb') as f:\n",
    "        unit_cells, unit_cells_EOS = pickle.load(f)\n",
    "    unit_cells_loaded = True\n",
    "    print(\"Loaded unit cells from cache\")\n",
    "except Exception as inst:\n",
    "    print(inst)\n",
    "    print(\"Can't load unit cells from cache, generating them\")\n",
    "    unit_cells_EOS = dict()\n",
    "    unit_cells = dict()\n",
    "\n",
    "defects_list = []\n",
    "for dataset in tqdm(training_datasets):\n",
    "    defects = read_defects_descriptions(StorageResolver()[\"csv_cif\"] / dataset)\n",
    "    materials = defects.base.unique()\n",
    "    assert len(materials) == 1\n",
    "    material = materials[0]\n",
    "    cell = defects.cell.unique()\n",
    "    assert len(cell) == 1\n",
    "    cell = cell[0]\n",
    "    # We have two MoS2/WSe2 unit cells with slightly different height,\n",
    "    # both are valid and there is no need to include them here\n",
    "    if not unit_cells_loaded:\n",
    "        unit_cells[material] = get_unit_cell(StorageResolver()[\"csv_cif\"] / dataset, materials)[material]\n",
    "        unit_cells_EOS[material] = EOS().get_augmented_struct(unit_cells[material])\n",
    "    defects_list.append(defects)\n",
    "if not unit_cells_loaded:\n",
    "    with open(inference_unit_cells_file, 'wb') as f:\n",
    "        pickle.dump((unit_cells, unit_cells_EOS), f)\n",
    "defects_pd = pd.concat(defects_list, axis=0)\n",
    "if 'pbc' in defects_pd.columns:\n",
    "    defects_pd = defects_pd.drop(columns=['pbc'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some hashable magic, we get the set of all point defects for each base material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import namedtuple\n",
    "SubstitutionDefect = namedtuple('substitution_defect', ['type', 'from_', 'to'])\n",
    "VacancyDefect = namedtuple('vacancy_defect', ['type', 'element'])\n",
    "def to_named_tuple(dict_):\n",
    "    if dict_['type'] == 'substitution':\n",
    "        return SubstitutionDefect(dict_['type'], dict_['from'], dict_['to'])\n",
    "    elif dict_['type'] == 'vacancy':\n",
    "        return VacancyDefect(**dict_)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown defect type {dict_['type']}\")\n",
    "available_defects = defects_pd.groupby(['base', 'cell']).apply(lambda x: set(map(to_named_tuple, chain(*x.defects))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two options for data acquisition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: generate the structures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of code for creating the structure generation interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_supercells = dict()\n",
    "for material in available_defects.index:\n",
    "    reference_supercells[material] = unit_cells[material[0]].copy()\n",
    "    reference_supercells[material].make_supercell(material[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_labels = list(map(lambda x: f\"{x[0]}, {x[1][0]}x{x[1][1]} supercell\", available_defects.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(defect_tuple):\n",
    "    if defect_tuple.type == 'substitution':\n",
    "        return f\"{defect_tuple.from_} -> {defect_tuple.to}\"\n",
    "    elif defect_tuple.type == 'vacancy':\n",
    "        return f\"{defect_tuple.element} vacancy\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown defect type {defect_tuple.type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_selection = widgets.RadioButtons(options=zip(material_labels, available_defects.index), description='Base material')\n",
    "total_structures_selection = widgets.IntSlider(min=1, max=100, step=1, value=100)\n",
    "total_defects_selection = widgets.IntSlider(min=0, max=15, step=1, value=1)\n",
    "max_defect_counts_selection = dict()\n",
    "\n",
    "structure_plots_output = widgets.Output()\n",
    "rng = np.random.default_rng(42)\n",
    "image_widget = widgets.Image(format='png', width=700, height=300,\n",
    "                             layout=widgets.Layout(object_fit='contain'))\n",
    "\n",
    "reference_atoms = dict()\n",
    "for material, supercell in reference_supercells.items():\n",
    "    reference_atoms[material] = AseAtomsAdaptor.get_atoms(supercell)\n",
    "\n",
    "def read_max_defect_counts_selection():\n",
    "    \"\"\"\n",
    "    Reads the widget and returns a dict with max defect counts for each defect type\n",
    "    suitable for the generate_structure_with_random_defects function\n",
    "    \"\"\"\n",
    "    max_defect_counts = defaultdict(dict)\n",
    "    for defect, count_widget in max_defect_counts_selection.items():\n",
    "        if defect.type == 'substitution':\n",
    "            max_defect_counts[defect.from_][defect.to] = count_widget.value\n",
    "        else:\n",
    "            max_defect_counts[defect.element][\"Vacancy\"] = count_widget.value\n",
    "    return max_defect_counts\n",
    "\n",
    "def plot_structures():\n",
    "    base_material = base_selection.value\n",
    "    max_defect_counts = read_max_defect_counts_selection()\n",
    "    backend = matplotlib.get_backend()\n",
    "    try:\n",
    "        matplotlib.use('agg')\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(7, 3), dpi=300, layout=\"constrained\")\n",
    "        try:\n",
    "            example_defect = generate_structure_with_random_defects(total_defects_selection.value, max_defect_counts,\n",
    "                                                                    reference_supercells[base_material], rng, False)\n",
    "            atoms = AseAtomsAdaptor.get_atoms(example_defect)\n",
    "            plot_atoms(atoms, ax=axes[1])\n",
    "        except InconsistentDefectCount:\n",
    "            axes[1].text(0.5, 0.5,\n",
    "                    \"Can't generate the requested number of defects,\\nincrease the max counts\",\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "        \n",
    "        plot_atoms(reference_atoms[base_material], ax=axes[0])\n",
    "        axes[0].set_title(\"Pristine structure\")\n",
    "        axes[1].set_title(\"Example structure with defects\")\n",
    "        for ax in axes:\n",
    "            ax.set_axis_off()\n",
    "        img_buf = io.BytesIO()\n",
    "        fig.savefig(img_buf, format='png')\n",
    "        plt.close(fig)\n",
    "        image_widget.value = img_buf.getvalue()\n",
    "    finally:\n",
    "        matplotlib.use(backend)\n",
    "\n",
    "def prepare_defect_sliders(base_material):\n",
    "    max_defect_counts_selection.clear()\n",
    "    for defect in available_defects[base_material]:\n",
    "        max_defect_counts_selection[defect] = widgets.IntSlider(min=0, max=15, step=1, value=1, description=get_label(defect))\n",
    "        max_defect_counts_selection[defect].observe(plot_structures_watcher)\n",
    "\n",
    "    controls.children = [base_selection,\n",
    "                         widgets.Label(\"Max counts for each defect type:\"),\n",
    "                         *max_defect_counts_selection.values(),\n",
    "                         widgets.Label(\"Total defects:\"),\n",
    "                         total_defects_selection,\n",
    "                         widgets.Label(\"Total structures to generate:\"),\n",
    "                         total_structures_selection]\n",
    "    plot_structures()\n",
    "\n",
    "def select_defects(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        prepare_defect_sliders(change['owner'].value)\n",
    "\n",
    "def plot_structures_watcher(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        plot_structures()\n",
    "\n",
    "base_selection.observe(select_defects)\n",
    "\n",
    "controls = widgets.VBox([base_selection])\n",
    "interface = widgets.HBox([controls, image_widget])\n",
    "prepare_defect_sliders(base_selection.value)\n",
    "total_defects_selection.observe(plot_structures_watcher)\n",
    "display(interface)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you should see widgets allowing you to specify the defects to generate. Once you are happy with the generation options, continue with notebook. If you don't see the widgets, you probably have a problem with [ipywidgets](https://ipywidgets.readthedocs.io/en/stable/) and can specify the parameters below by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_material = base_selection.value\n",
    "# material = ('MoS2', (8, 8, 1))\n",
    "# material should be a tuple of (formula, supercell_size) from available_defects.index\n",
    "# The models don't generalise to chemically different materials\n",
    "# Generalising to different supercell sizes is possible but not well tested\n",
    "if material not in available_defects.index:\n",
    "    raise ValueError(f\"Unknown material {material}, use one in \\n{available_defects.index}\")\n",
    "\n",
    "# The number of point defects your structures will have\n",
    "total_defects = total_defects_selection.value\n",
    "# total_defects = 3\n",
    "\n",
    "# The maximum number of each defect type your structures will have\n",
    "max_defect_counts = read_max_defect_counts_selection()\n",
    "# max_defect_counts = {'S': {'Se': 1, 'Vacancy': 1}, 'Mo': {'Vacancy': 1, 'W': 1}}\n",
    "\n",
    "# The number of structures to generate\n",
    "total_structures = total_structures_selection.value\n",
    "# total_structures = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_supercell = reference_supercells[base_material]\n",
    "structures = []\n",
    "for i in trange(total_structures):\n",
    "    structures.append(generate_structure_with_random_defects(total_defects, max_defect_counts,\n",
    "                                                             reference_supercell, rng, False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: upload\n",
    "Upload your own structures for the model to predict. Note that for the predictions to make sense, the base materials and point defect types must be present in the training dataset.\n",
    "1. Unit cell in `.cif` format. [Example](../datasets/others/upload_example/MoS2.cif)\n",
    "2. Structures as a `.zip` archive with `.cif` structures inside. [Example](../datasets/others/upload_example/structures.zip)\n",
    "3. Supercell size in unit cells: self-explanatory, but don't forget. Use 1x1 if your unit cell is in fact a supercell\n",
    "4. Push the button\n",
    "\n",
    "**It's safe to run this code if you generated the structures, it won't do anything without pressing the button**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit_cell_uploader = widgets.FileUpload(accept='.cif', multiple=False, description=\"Unit cell .cif\")\n",
    "# structures_uploader = widgets.FileUpload(accept='.zip', multiple=False, description=\"Structures\")\n",
    "# The widgets crash CRP (as of 22.06.2023)\n",
    "# https://mm.rolos.dev/rolos-team/pl/nod5setpjibb7chnfqqim93h7a\n",
    "\n",
    "# Upload the files using the interface and specify the paths here\n",
    "unit_cell_path = \"../datasets/others/upload_example/MoS2.cif\"\n",
    "structures_path = \"../datasets/others/upload_example/structures.zip\"\n",
    "unit_cell_uploader = widgets.Label(f\"[Edit the cell to change] Unit cell: {unit_cell_path}\")\n",
    "structures_uploader = widgets.Label(f\"[Edit the cell to change] Structures: {structures_path}\")\n",
    "\n",
    "supercell_selector_style = {'description_width': 'initial'}\n",
    "supercell_x = widgets.BoundedIntText(description=\"Supercell size in unit cells:\", value=8, min=1,\n",
    "                                     layout=widgets.Layout(width='200px'), style=supercell_selector_style)\n",
    "supercell_y = widgets.BoundedIntText(description=\"x\", value=8, min=1,\n",
    "                                     layout=widgets.Layout(width='50px'), style=supercell_selector_style)\n",
    "process_upload_button = widgets.Button(description=\"Process upload\")\n",
    "upload_interface = widgets.HBox([supercell_x, supercell_y, process_upload_button])\n",
    "def process_upload(button):\n",
    "    print(\"Loading the data...\")\n",
    "    unit_cell = Structure.from_file(unit_cell_path)\n",
    "    uploaded_material = (unit_cell.formula, (supercell_x.value, supercell_y.value, 1))\n",
    "    reference_supercell = unit_cell.copy()\n",
    "    reference_supercell.make_supercell(uploaded_material[1])\n",
    "    global structures\n",
    "    structures = []\n",
    "    with zipfile.ZipFile(structures_path, \"r\") as structures_arhive:\n",
    "        for name in structures_arhive.namelist():\n",
    "            cif_data = structures_arhive.read(name).decode(\"ascii\")\n",
    "            this_structure_file = CifParser.from_string(cif_data)\n",
    "            new_structures = this_structure_file.get_structures(primitive=False)\n",
    "            for structure in new_structures:\n",
    "                if not np.allclose(structure.lattice.matrix, reference_supercell.lattice.matrix):\n",
    "                    raise ValueError(\"Structure and reference supercell have different lattices\")\n",
    "                structures.append(structure)\n",
    "    global base_material\n",
    "    base_material = uploaded_material\n",
    "    global total_defects\n",
    "    total_defects = None\n",
    "    global max_defect_counts\n",
    "    max_defect_counts = None\n",
    "    global total_structures\n",
    "    total_structures = len(structures)\n",
    "    unit_cells_EOS[base_material[0]] = EOS().get_augmented_struct(unit_cell)\n",
    "    print(f\"Loaded {len(structures)} structures of {uploaded_material[1][0]}x{uploaded_material[1][1]} {uploaded_material[0]}\")\n",
    "process_upload_button.on_click(process_upload)\n",
    "display(unit_cell_uploader, structures_uploader, upload_interface)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and plot the sparse structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_defects is not None:\n",
    "    total_defects_label = str(total_defects) + \" \"\n",
    "else:\n",
    "    total_defects_label = \"\"\n",
    "defects_to_plot = min(5, len(structures))\n",
    "fig, axes = plt.subplots(1, defects_to_plot, figsize=(defects_to_plot * 2, 2),\n",
    "                         layout=\"tight\")\n",
    "for i in range(defects_to_plot):\n",
    "    atoms = AseAtomsAdaptor.get_atoms(structures[i])\n",
    "    plot_atoms(atoms, ax=axes[i])\n",
    "    axes[i].set_axis_off()\n",
    "fig.suptitle(f\"Example {base_material[0]} structures with {total_defects_label}defects\")\n",
    "fig.canvas.header_visible = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataFrame():\n",
    "    \"\"\"\n",
    "    A class that mimics a pandas dataframe of zeros\n",
    "    \"\"\"\n",
    "    class DummyIndexer():\n",
    "        def __getitem__(self, *args, **kwargs):\n",
    "            return 0\n",
    "    @property\n",
    "    def loc(self, *args, **kwargs):\n",
    "        return self.DummyIndexer()\n",
    "\n",
    "# Prepare dummy single atom energies\n",
    "# They don't affect the sparse representations of structures.\n",
    "# Their role is to transform the total potential energy of the structure\n",
    "# formation energy of the defects. Our models are\n",
    "# trained to predict directly the formation energy per site\n",
    "single_atom_energies_dummy = DummyDataFrame()\n",
    "\n",
    "# Compute the sparse representations\n",
    "sparse_structures = []\n",
    "for structure in tqdm(structures):\n",
    "    sparse_structures.append(get_sparse_defect(structure, unit_cells_EOS[base_material[0]], base_material[1], single_atom_energies_dummy)[0])\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, defects_to_plot, figsize=(defects_to_plot * 2, 2))\n",
    "for i in range(defects_to_plot):\n",
    "    atoms = AseAtomsAdaptor.get_atoms(sparse_structures[i])\n",
    "    plot_atoms(atoms, ax=axes[i])\n",
    "    axes[i].set_axis_off()\n",
    "fig.tight_layout()\n",
    "fig.suptitle(f\"Sparse representations for the example {base_material[0]} structures with {total_defects_label}defects\")\n",
    "fig.canvas.header_visible = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sparse structure in the text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_structures[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(columns=[\"structure\", \"sparse_structure\"] + list(predictors.keys()))\n",
    "predictions[\"structure\"] = structures\n",
    "predictions[\"sparse_structure\"] = sparse_structures\n",
    "for target, predictor in predictors.items():\n",
    "    predictions[target] = predictor.predict_structures(sparse_structures)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore our predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both formation energy per site and HOMO-LUMO gap are in eV\n",
    "predictions.hist(figsize=(10, 5), bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"tight\")\n",
    "ax.scatter(predictions[\"formation_energy_per_site\"], predictions[\"homo_lumo_gap_min\"])\n",
    "ax.set_xlabel(\"Formation energy per site, eV\")\n",
    "ax.set_ylabel(\"HOMO-LUMO gap, ev\");\n",
    "fig.canvas.header_visible = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and plot structures across the property range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_to_plot = 5\n",
    "fig = plt.figure(figsize=(structures_to_plot*2, len(predictors.keys())*2), layout=\"constrained\")\n",
    "subfigs = fig.subfigures(nrows=len(predictors.keys()), ncols=1)\n",
    "\n",
    "for target, subfig in zip(predictors.keys(), subfigs):\n",
    "    sorted_predictions = predictions.sort_values(target, ignore_index=True)\n",
    "    values_to_plot = np.linspace(sorted_predictions[target].iloc[0], sorted_predictions[target].iloc[-1], num=structures_to_plot)\n",
    "    indices_to_plot = np.searchsorted(sorted_predictions[target], values_to_plot)\n",
    "    subfig.suptitle(target)\n",
    "    axes = subfig.subplots(nrows=1, ncols=len(indices_to_plot))\n",
    "    for index, ax in zip(indices_to_plot, axes):\n",
    "        plot_atoms(AseAtomsAdaptor.get_atoms(sorted_predictions.loc[index, \"structure\"]), ax=ax)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(f\"{sorted_predictions.loc[index, target]:.3f} eV\")\n",
    "fig.canvas.header_visible = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Data catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import uuid\n",
    "try:\n",
    "    from rolos_sdk import Dataframe, DataStorageInterface, DataStorageType, TableColumn\n",
    "    from rolos_sdk.structures.object.pymatgen import PyMatGenObject\n",
    "\n",
    "    def upload_data(table_data: List[List], table_schema: List[TableColumn], name: str) -> None:\n",
    "        with DataStorageInterface.create(DataStorageType.Datacat) as storage:\n",
    "            with Dataframe(name=name, storage=storage, schema=table_schema) as frame:\n",
    "                frame.insert(table_data)\n",
    "\n",
    "    schema = [TableColumn(name=\"structure\", type=PyMatGenObject),\n",
    "              TableColumn(name=\"sparse_structure\", type=PyMatGenObject)] + \\\n",
    "             [TableColumn(name=target, type=float) for target in predictors.keys()]\n",
    "    dataset_name = f\"Predicted {base_material[0]} structures with {total_defects_label}defects {uuid.uuid4()}\"\n",
    "    upload_data(predictions.values.tolist(), schema, dataset_name)\n",
    "    print(f'Uploaded \"{dataset_name}\"')\n",
    "except ImportError:\n",
    "    print(\"Can't import the SDK, most likely because you are not running on CRP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2d-defects-potential-learning-pYjw2mkT-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
